{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ======================================================================\n",
    "\n",
    "# 75.06/95.58 Organización de Datos\n",
    "\n",
    "# Primer Cuatrimestre de 2018\n",
    "\n",
    "# Trabajo Práctico 1: Análisis Exploratorio\n",
    "\n",
    "## Integrantes:\n",
    "\n",
    "Marcelo Iannuzzi\n",
    "\n",
    "Gabriel La Torre\n",
    "\n",
    "Andrés Silvestri\n",
    "\n",
    "## ======================================================================\n",
    "\n",
    "# Introducción\n",
    "\n",
    "Este trabajo está enfocado en hacer un primer análisis de los datos ofrecidos por la empresa Navent, de manera que encontremos particularidades que puedan ser de interés para dicha entidad.\n",
    "\n",
    "Siendo este el caso, lo primero que vamos a hacer es interiorizarnos de uno de los pilares que tiene la ciencia de datos, el negocio.\n",
    "\n",
    "# ¿De qué se encarga Navent?\n",
    "\n",
    "Navent es una empresa que tiene dos misiones muy bien marcadas que se traducen en dos negocios distintos: \"Ayudamos a que las personas logren dos de los anhelos más importantes de la vida. Encontrar un Empleo y un Hogar.\"\n",
    "\n",
    "Es decir que un negocio son los recursos humanos y el otro negocio es el negocio de bienes raíces.\n",
    "\n",
    "Dicho esto, primero haremos un primer análisis de los datos recibidos para saber con qué información lidiamos y empezaremos a proponernos preguntas que puedan ser de utilidad para la empresa. Posteriormente intentaremos buscar respuesta a esas preguntas en base a los datos obtenidos y propondremos una visualización que ayude a su rápido ententimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ======================================================================\n",
    "\n",
    "# Organización del Informe:\n",
    "\n",
    "A continuación enunciaremos en primer instancia como tendremos dividido el informe que llevaremos a cabo.\n",
    "Lo primero será el armado de los datos, luego haremos análisis sobre los postulantes, los avisos por separado y luego junto a la información provista de las visitas y los postulaciones un análisis que englobe todo esto. Con esta idea tratamo de abordar en primer instancia la información que tenemos por separado, ver que se puede obtener de cada parte y luego unificarla para poder trabajarla unificando criterios.\n",
    "\n",
    "## 1 - Importación y estructura de los datos:\n",
    "\n",
    "    1.1 - Configuración básica y obtención de los datasets.\n",
    "    1.2 - Procesamiento general de las información y armado básico.\n",
    "    1.3 - Resumen y cuestiones a tener en cuenta sobre el informe.\n",
    "    \n",
    "## 2 - Análisis sobre los postulantes registrados:\n",
    "\n",
    "    2.1 - Análisis de datasets dados por properati\n",
    "    \n",
    "## 3 - Análisis sobre los avisos publicados:\n",
    "\n",
    "    3.1 - Análisis de datasets dados por properati\n",
    "    \n",
    "## 4 - Análisis sobre las visitas y las postulaciones:\n",
    "\n",
    "    4.1 - Análisis de datasets dados por properati\n",
    "    \n",
    "## 5 - Análisis resultante que engloba lo antes mencionado:\n",
    "\n",
    "    5.1 - Análisis de datasets dados por properati\n",
    "\n",
    "## ======================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Importación y estructura de los datos:\n",
    "\n",
    "## 1.1 - Configuración básica y obtención de los datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTACIÓN GENERAL DE LIBRERIAS Y VISUALIZACIÓN DE DATOS (matplotlib y seaborn)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as DT\n",
    "%matplotlib inline\n",
    "plt.style.use('default') \n",
    "sns.set(style=\"whitegrid\") \n",
    "#plt.rcParams['figure.figsize'] = (20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OBTENEMOS TODA LA INFORMACIÓN DE LOS DIFERENTES CSV.\n",
    "nivel_educativo = pd.read_csv('fiuba_1_postulantes_educacion.csv')\n",
    "nacimiento_genero = pd.read_csv('fiuba_2_postulantes_genero_y_edad.csv')\n",
    "vistas_avisos = pd.read_csv('fiuba_3_vistas.csv')\n",
    "postulaciones = pd.read_csv('fiuba_4_postulaciones.csv')\n",
    "avisos_online = pd.read_csv('fiuba_5_avisos_online.csv')\n",
    "avisos_detalle = pd.read_csv('fiuba_6_avisos_detalle.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ======================================================================\n",
    "\n",
    "## 1.2 - Procesamiento general de las información y armado básico.\n",
    "\n",
    "Para cada una de las diferentes fuentes de datos haremos diversos tratamientos, tanto para purificar los datos como para filtrar aquellos que más nos ineresan, se hará una breve explicación sobre lo que se trata de obtener en cada caso a modo de resumen, como así también se comentara cada linea de código para que se pueda interpretar qué es lo que se decidió hacer en cada caso.\n",
    "\n",
    "### 1.2.1 - Postulantes: \n",
    "\n",
    "Lo primero que vamos a tratar es ver que hay registros repetidos (debido a que cada postulante tiene varios niveles educativos registrados), por otro lado haremos un cálculo de la edad que posee cada postulante y los filtraremos por aquellos que están en un rango de edad coherente (no al trabajo infantil y tampoco a las personas que sobrepasan los cien años). Sobre la edad decidimos agregar una columna que nos represente el rango al que pertenece la persona, siendo un criterio arbitrario y subjetivo pero que nos servirá para análisis posteriores. También hacemos una pequeña limpieza sobre los niveles de educación como así también un filtrado de duplicados cuando no nos interese el apartado educativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UNIFICACIÓN BÁSICA SOBRE LA INFORMACIÓN DE LOS POSTULANTES.\n",
    "postulantes = nivel_educativo.merge(nacimiento_genero,left_on='idpostulante', right_on='idpostulante',how='outer')\n",
    "## TRANSFORMAMOS A DATETIME LA FECHA DE NACIMIENTO DE LOS POSTULANTES.\n",
    "postulantes['fechanacimiento'] = pd.to_datetime(postulantes['fechanacimiento'], errors = 'coerce')\n",
    "## CALCULAMOS LA EDAD DE LOS POSTULANTES CON UN VALOR NUMÉRICO.\n",
    "now = pd.Timestamp(DT.datetime.now())\n",
    "postulantes['edad'] = (now - postulantes['fechanacimiento']).astype('<m8[Y]')\n",
    "## SOLO CONSIDERAMOS COMO VÁLIDOS AQUELLOS POSTULANTES DE ENTRE 17 Y 100 AÑOS.\n",
    "postulantes = postulantes[(postulantes['edad'] > 17) & (postulantes['edad'] < 100)]\n",
    "## ARMAMOS UNA COLUMNA SOBRE EL RANGO DE EDAD QUE TIENEN LOS POSTULANTES.\n",
    "postulantes['rango_edad'] = 'abc'\n",
    "postulantes.loc[postulantes.edad < 20, 'rango_edad'] = '< 20'\n",
    "postulantes.loc[postulantes.edad > 65, 'rango_edad'] = '> 65'\n",
    "postulantes.loc[postulantes.rango_edad == 'abc', 'rango_edad'] = '> 65'\n",
    "## ARMAMOS LOS DIFERENTES RANGOS DE EDAD QUE SE PUEDEN IR DANDO ENTRE LOS POSTULANTES.\n",
    "postulantes.loc[(postulantes.edad >= 20) & (postulantes.edad <= 24), 'rango_edad'] = '20 ~ 25'\n",
    "postulantes.loc[(postulantes.edad >= 25) & (postulantes.edad <= 29), 'rango_edad'] = '25 ~ 30'\n",
    "postulantes.loc[(postulantes.edad >= 30) & (postulantes.edad <= 34), 'rango_edad'] = '30 ~ 35'\n",
    "postulantes.loc[(postulantes.edad >= 35) & (postulantes.edad <= 39), 'rango_edad'] = '35 ~ 40'\n",
    "postulantes.loc[(postulantes.edad >= 40) & (postulantes.edad <= 44), 'rango_edad'] = '40 ~ 45'\n",
    "postulantes.loc[(postulantes.edad >= 45) & (postulantes.edad <= 49), 'rango_edad'] = '45 ~ 50'\n",
    "postulantes.loc[(postulantes.edad >= 50) & (postulantes.edad <= 54), 'rango_edad'] = '50 ~ 55'\n",
    "postulantes.loc[(postulantes.edad >= 55) & (postulantes.edad <= 59), 'rango_edad'] = '55 ~ 60'\n",
    "postulantes.loc[(postulantes.edad >= 60) & (postulantes.edad <= 64), 'rango_edad'] = '60 ~ 65'\n",
    "## ANALIZAMOS LOS NIVELES EDUCATIVOS Y UNIFICAMOS CRITERIOS SOBRE ESTOS.\n",
    "postulantes.loc[postulantes.nombre == 'Terciario/Técnico', 'nombre'] = 'Terciario'\n",
    "postulantes.loc[postulantes.nombre == 'Terciario/Tecnico', 'nombre'] = 'Terciario'\n",
    "## PARA LOS ANÁLISIS DONDE EL NIVEL EDUCATIVO NO ES RELEVANTE HACEMOS UNA LIMPIEZA DE DUPLICADOS.\n",
    "postulantes_unicos = postulantes.drop_duplicates(subset=\"idpostulante\", keep='first', inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 - Avisos: \n",
    "\n",
    "Lo primero que vamos a tratar con respecto a estos datos es que hay unos pocos que son fuera de CABA y GBA (exactamente 2) esto nos lleva a eliminarlos porque pierde sentido su análisis. Por otro lado vemos que hay varias formas de referirce al Gran Buenos Aires, lo que nos lleva a unificarlo. Haremos un merge con los avisos online teniendo así toda la información pertinente en una única fuente de datos, así también podremos diferenciar cuando un aviso está online y cuando no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LIMPIAMOS AQUELLOS AVISOS QUE NO PERTENECEN NI A CABA NI A GBA.\n",
    "avisos_detalle = avisos_detalle[(avisos_detalle['nombre_zona'] != 'Buenos Aires (fuera de GBA)')]\n",
    "## UNIFICAMOS CRITERIOS A LA HORA DE NOMBRAR AL GRAN BUENOS AIRES.\n",
    "avisos_detalle.loc[avisos_detalle.nombre_zona == 'GBA Oeste', 'nombre_zona'] = 'Gran Buenos Aires'\n",
    "## AGREGAMOS UN DATO PARA DISTINGUIR LOS AVISOS ONLINE.\n",
    "avisos_online['esta_online'] = 'si'\n",
    "## UNIFICAMOS LOS DETALLES DE LOS AVISOS CON LOS AVISOS ONLINE.\n",
    "avisos_detalle_completo = avisos_detalle.merge(avisos_online,left_on='idaviso', right_on='idaviso',how='left')\n",
    "## PONEMOS EN 'NO' TODOS AQUELLOS AVISOS QUE NO ESTAN ONLINE.\n",
    "avisos_detalle_completo.loc[avisos_detalle_completo.esta_online != 'si', 'esta_online'] = 'no'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 - Visitas: \n",
    "\n",
    "Sobre esta información lo primero que queremos hacer es transformar la fecha a un formato que podamos manejar con propiedad, en segunda instancia nos parece interesante obtener el día de la semana donde se produjo la visita. Luego debemos de ordenar los días para que a futuro sea más lógica la graficación. \n",
    "\n",
    "Luego le incorporamos la información de los detalles de cada aviso, como así también hacemos un filtro sobre las ingenierías que más relevancia muestran en los avisos, como así también una limpieza sobre los acentos tanto para la denominación de la empresa como para el area sobre la que hace referencia el aviso. Unificamos también los datos referidos a ADECCO, el cual se divercifica en zonas pero para nuestro análisis termina siendo lo mismo.\n",
    "\n",
    "Por último y no menos importante es necesario empezar a obtener la información de quién es la persona que ha decidido visitar la publicación, con lo que terminamos unificando la información con los datos de los postulantes previamente adquiridos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLANTEMOAS LA FECHA EN QUE SE VISITAS EL AVISO COMO UNA NUEVA COLUMNA DATETIME.\n",
    "vistas_avisos['fecha_vista'] = pd.to_datetime(vistas_avisos['timestamp'], errors = 'coerce')\n",
    "## HACEMOS UNA DIFERENCIA ENTRE EL DÍA DE LA SEMANA EN EL QUE SE LLEVÓ A CABO LA VISITA.\n",
    "vistas_avisos['dia_semana'] = vistas_avisos['fecha_vista'].dt.weekday_name\n",
    "## CREAMOS UN ORDENAMIENTO PARA LOS DÍAS DE LA SEMANA, COSA DE QUE NO QUEDE ORDENADA POR VALORES ASCENDENTES.\n",
    "vistas_avisos['dia_semana'] = pd.Categorical(vistas_avisos['dia_semana'], categories=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday'], ordered=True)\n",
    "vistas_dias = vistas_avisos['dia_semana'].value_counts()\n",
    "vistas_dias = vistas_dias.sort_index()\n",
    "## LE AGREGAMOS EL DETALLE DE LOS AVISOS A LAS VISITAS QUE ESTAMOS TRABAJANDO.\n",
    "vistas_avisos_completas = vistas_avisos.merge(avisos_detalle_completo,left_on='idAviso', right_on='idaviso',how='left')\n",
    "## HACEMOS UNA LIMPIEZA SOBRE ALGUNOS NOMBRE EN LAS VISITAS.\n",
    "vistas_avisos_completas.loc[vistas_avisos_completas.nombre_area == 'Ingeniería  Eléctrica y Electrónica', 'nombre_area'] = 'Ingeniería Eléctrica y Electrónica'\n",
    "vistas_avisos_completas.loc[vistas_avisos_completas.nombre_area == 'Ingeniería  Mecánica', 'nombre_area'] = 'Ingeniería Mecánica'\n",
    "vistas_avisos_completas.loc[vistas_avisos_completas.nombre_area == 'Ingeniería  Industrial', 'nombre_area'] = 'Ingeniería Industrial'\n",
    "vistas_avisos_completas.loc[vistas_avisos_completas.nombre_area == 'Ingeniería  Automotriz', 'nombre_area'] = 'Ingeniería Automotriz'\n",
    "vistas_avisos_completas.loc[vistas_avisos_completas.nombre_area == 'Ingeniería  Metalurgica', 'nombre_area'] = 'Ingeniería Metalurgica'\n",
    "## LIMPIAMOS LOS ACENTOS PARA EL NOMBRE_AREA QUE NOS TRAEN PROBLEMAS A LA HORA DE GRAFICAR.\n",
    "vistas_avisos_completas['nombre_area'] = vistas_avisos_completas['nombre_area'].str.replace(\"á\", \"a\")\n",
    "vistas_avisos_completas['nombre_area'] = vistas_avisos_completas['nombre_area'].str.replace(\"é\", \"e\")\n",
    "vistas_avisos_completas['nombre_area'] = vistas_avisos_completas['nombre_area'].str.replace(\"í\", \"i\")\n",
    "vistas_avisos_completas['nombre_area'] = vistas_avisos_completas['nombre_area'].str.replace(\"ó\", \"o\")\n",
    "vistas_avisos_completas['nombre_area'] = vistas_avisos_completas['nombre_area'].str.replace(\"ú\", \"u\")\n",
    "## LIMPIAMOS LOS ACENTOS PARA LA DENOMINACION_EMPRESA QUE NOS TRAEN PROBLEMAS A LA HORA DE GRAFICAR.\n",
    "vistas_avisos_completas['denominacion_empresa'] = vistas_avisos_completas['denominacion_empresa'].str.replace(\"á\", \"a\")\n",
    "vistas_avisos_completas['denominacion_empresa'] = vistas_avisos_completas['denominacion_empresa'].str.replace(\"é\", \"e\")\n",
    "vistas_avisos_completas['denominacion_empresa'] = vistas_avisos_completas['denominacion_empresa'].str.replace(\"í\", \"i\")\n",
    "vistas_avisos_completas['denominacion_empresa'] = vistas_avisos_completas['denominacion_empresa'].str.replace(\"ó\", \"o\")\n",
    "vistas_avisos_completas['denominacion_empresa'] = vistas_avisos_completas['denominacion_empresa'].str.replace(\"ú\", \"u\")\n",
    "## HACEMOS UN FILTRADO SOBRE LAS AREAS QUE SE RELACIONAN CON INGENIERÍA.\n",
    "filtrado_ingenieria = vistas_avisos_completas[vistas_avisos_completas['nombre_area'].str.contains(\"Ingen\", na=False)]\n",
    "filtrado_ingenieria['nombre_area'] = filtrado_ingenieria['nombre_area'].str.replace(\"Ingenieria\", \"I.\")\n",
    "filtrado_ingenieria['nombre_area'] = filtrado_ingenieria['nombre_area'].str.replace(\"Ingenierias\", \"I.\")\n",
    "## COMO LOS NOMBRES SUELEN SER MUY LARGOS LOS LIMPIAMOS PARA QUE SEA MÁS LEGIBLE EL GRÁFICO.\n",
    "filtrado_ingenieria = filtrado_ingenieria[filtrado_ingenieria['nombre_area'].str.contains(\"I. \", na=False)]\n",
    "## NOS QUEDAMOS CON LAS DIEZ MÁS RELEVANTES.\n",
    "diez_ingenierias = filtrado_ingenieria['nombre_area'].value_counts()[:10]\n",
    "## PARA COMPARAR TAMBIÉN BUSCAMOS AQUELLLAS AREAS EN GENERAL QUE TIENEN MÁS VISITAS.\n",
    "top_visitados_area= vistas_avisos_completas['nombre_area'].value_counts()[:10]\n",
    "## VIENDO LOS DATOS VEMOS QUE ADECCO TIENE MUCHOS DATOS PERO SEPARADOS SEGÚN ZONAS, LOS UNIFICAMOS PARA MAYOR CLARIDAD.\n",
    "vistas_avisos_completas.loc[vistas_avisos_completas.denominacion_empresa.str.contains(\"Adecco\")==True, 'denominacion_empresa'] = 'Adecco'\n",
    "## VEMOS LAS EMPRESAS QUE TIENEN UNA MAYOR CANTIDAD DE VISITAS.\n",
    "diez_vistas_empresas = vistas_avisos_completas['denominacion_empresa'].value_counts()[:10]\n",
    "## PARAMETRIZAMOS LAS FECHAS TANTO EL DÍA COMO EL MES PARA ESTE FUENTE DE DATOS COMPLETA.\n",
    "vistas_avisos_completas['fecha_vista_completa'] = pd.to_datetime(vistas_avisos_completas['timestamp'], errors = 'coerce')\n",
    "vistas_avisos_completas['dia_semana_completa'] = vistas_avisos_completas['fecha_vista_completa'].dt.weekday_name\n",
    "vistas_avisos_completas['mes_completa'] = vistas_avisos_completas['fecha_vista_completa'].dt.month\n",
    "vistas_avisos_completas['dia_completa'] = vistas_avisos_completas['fecha_vista_completa'].dt.day\n",
    "## OBTENEMOS LA INFORMACION DE QUIEN HA HECHO LA VISITA.\n",
    "vistas_avisos_completas = vistas_avisos_completas.merge(postulantes_unicos,left_on='idpostulante', right_on='idpostulante',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 - Postulaciones: \n",
    "\n",
    "Con estos datos vamos a ver las postulaciones a los avisos propiamente dichos, lo primero sería hacer algo similar a lo que se hizo con las visitas, transformar la fecha a un formato apropiado para poder trabajarla, nuevamente como segunda medida obtenemos el día de la semana al que corresponde cada postulación. Luego debemos de ordenar los días de la semana para que sea más lógica la graficación, también nificamos con los detalles que tienen los avisos cosa de poder contrastar mayor información, como así también aplicamos una limpieza sobre los acentos tanto para el area como para la denominación de la empresa. \n",
    "\n",
    "Obtenemos también las diez areas con más postulaciones y las diez ingenierías con más postulaciones. Unificamos los datos referidos a ADECCO, el cual se divercifica en zonas pero para nuestro análisis termina siendo lo mismo. Luego esto nos lleva a tomar un listado de las diez empresas con mayor cantidad de postulaciones.\n",
    "\n",
    "Por último y no menos importante es necesario empezar a obtener la información de quién es la persona que se ha decidido postular, con lo que terminamos unificando la información con los datos de los postulantes previamente adquiridos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REDUCIMOS EL STRING QUE CORRESPONDE A LA FECHA SOLO HACIENDO REFERENCIA AL DÍA/MES/AÑO.\n",
    "postulaciones['fecha_postulado'] = postulaciones['fechapostulacion'].str.slice(0, 10)\n",
    "## LO TRANSFORMAMOS EN UN DATETIME COSA DE PODER TRABAJARLO MEJOR.\n",
    "postulaciones['fecha_postulado'] = pd.to_datetime(postulaciones['fecha_postulado'], errors = 'coerce')\n",
    "## OBTENEMOS EL DÍA DE LA SEMANA QUE CORRESPONDE A ESA POSTULACIÓN EN CUESTIÓN.\n",
    "postulaciones['dia_semana'] = postulaciones['fecha_postulado'].dt.weekday_name\n",
    "## CREAMOS UN ORDENAMIENTO PARA LOS DÍAS DE LA SEMANA, COSA DE QUE NO QUEDE ORDENADA POR VALORES ASCENDENTES.\n",
    "postulaciones['dia_semana'] = pd.Categorical(postulaciones['dia_semana'], categories=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday'], ordered=True)\n",
    "postulaciones_dias = postulaciones['dia_semana'].value_counts()\n",
    "postulaciones_dias = postulaciones_dias.sort_index()\n",
    "## LE AGREGAMOS EL DETALLE DE LOS AVISOS A LAS POSTULACIONES QUE ESTAMOS TRABAJANDO.\n",
    "postulaciones_avisos_completos = postulaciones.merge(avisos_detalle_completo,left_on='idaviso', right_on='idaviso',how='left')\n",
    "## LIMPIAMOS LOS ACENTOS SOBRE EL NOMBRE_AREA QUE NOS TRAEN PROBLEMAS A LA HORA DE GRAFICAR.\n",
    "postulaciones_avisos_completos['nombre_area'] = postulaciones_avisos_completos['nombre_area'].str.replace(\"á\", \"a\")\n",
    "postulaciones_avisos_completos['nombre_area'] = postulaciones_avisos_completos['nombre_area'].str.replace(\"é\", \"e\")\n",
    "postulaciones_avisos_completos['nombre_area'] = postulaciones_avisos_completos['nombre_area'].str.replace(\"í\", \"i\")\n",
    "postulaciones_avisos_completos['nombre_area'] = postulaciones_avisos_completos['nombre_area'].str.replace(\"ó\", \"o\")\n",
    "postulaciones_avisos_completos['nombre_area'] = postulaciones_avisos_completos['nombre_area'].str.replace(\"ú\", \"u\")\n",
    "## LIMPIAMOS LOS ACENTOS SOBRE LA DENOMINACIÓN_EMPRESA QUE NOS TRAEN PROBLEMAS A LA HORA DE GRAFICAR.\n",
    "postulaciones_avisos_completos['denominacion_empresa'] = postulaciones_avisos_completos['denominacion_empresa'].str.replace(\"á\", \"a\")\n",
    "postulaciones_avisos_completos['denominacion_empresa'] = postulaciones_avisos_completos['denominacion_empresa'].str.replace(\"é\", \"e\")\n",
    "postulaciones_avisos_completos['denominacion_empresa'] = postulaciones_avisos_completos['denominacion_empresa'].str.replace(\"í\", \"i\")\n",
    "postulaciones_avisos_completos['denominacion_empresa'] = postulaciones_avisos_completos['denominacion_empresa'].str.replace(\"ó\", \"o\")\n",
    "postulaciones_avisos_completos['denominacion_empresa'] = postulaciones_avisos_completos['denominacion_empresa'].str.replace(\"ú\", \"u\")\n",
    "## OBTENEMOS LAS DIEZ AREAS CON MÁS POSTULACIONES.\n",
    "top_postulaciones_area= postulaciones_avisos_completos['nombre_area'].value_counts()[:10]\n",
    "## LIMPIAMOS LOS NOMBRES DE LAS INGENIERÍAS QUE INTERVIENEN EN LA CUESTIÓN.\n",
    "postulaciones_avisos_completos.loc[postulaciones_avisos_completos.nombre_area == 'Ingeniería  Eléctrica y Electrónica', 'nombre_area'] = 'Ingeniería Eléctrica y Electrónica'\n",
    "postulaciones_avisos_completos.loc[postulaciones_avisos_completos.nombre_area == 'Ingeniería  Mecánica', 'nombre_area'] = 'Ingeniería Mecánica'\n",
    "postulaciones_avisos_completos.loc[postulaciones_avisos_completos.nombre_area == 'Ingeniería  Industrial', 'nombre_area'] = 'Ingeniería Industrial'\n",
    "postulaciones_avisos_completos.loc[postulaciones_avisos_completos.nombre_area == 'Ingeniería  Automotriz', 'nombre_area'] = 'Ingeniería Automotriz'\n",
    "postulaciones_avisos_completos.loc[postulaciones_avisos_completos.nombre_area == 'Ingeniería  Metalurgica', 'nombre_area'] = 'Ingeniería Metalurgica'\n",
    "## HACEMOS UN FILTRADO SOBRE EL NOMBRE DE AREA SEGÚN CORRESPONDA A INGENIERÍA.\n",
    "filtrado_postu_ingenieria = postulaciones_avisos_completos[postulaciones_avisos_completos['nombre_area'].str.contains(\"Ingen\", na=False)]\n",
    "filtrado_postu_ingenieria['nombre_area'] = filtrado_postu_ingenieria['nombre_area'].str.replace(\"Ingenieria\", \"I.\")\n",
    "filtrado_postu_ingenieria['nombre_area'] = filtrado_postu_ingenieria['nombre_area'].str.replace(\"Ingenierias\", \"I.\")\n",
    "filtrado_postu_ingenieria = filtrado_postu_ingenieria[filtrado_postu_ingenieria['nombre_area'].str.contains(\"I. \", na=False)]\n",
    "## TOMAMOS SOLO LAS DIEZ INGENIERÍAS QUE MAS RELEVANCIA MUESTREN.\n",
    "diez_ingenierias_postu = filtrado_postu_ingenieria['nombre_area'].value_counts()[:10]\n",
    "## VIENDO LOS DATOS VEMOS QUE ADECCO TIENE MUCHOS DATOS PERO SEPARADOS SEGÚN ZONAS, LOS UNIFICAMOS PARA MAYOR CLARIDAD.\n",
    "postulaciones_avisos_completos.loc[postulaciones_avisos_completos.denominacion_empresa.str.contains(\"Adecco\")==True, 'denominacion_empresa'] = 'Adecco'\n",
    "## TOMAMOS LAS DIEZ EMPRESAS CON MAYOR CANTIDAD DE POSTULACIONES.\n",
    "diez_postulaciones_empresas = postulaciones_avisos_completos['denominacion_empresa'].value_counts()[:10]\n",
    "## OBTENEMOS LA INFORMACIÓN DE QUIEN HA HECHO LA POSTULACIÓN.\n",
    "postulaciones_avisos_completos = postulaciones_avisos_completos.merge(postulantes_unicos,left_on='idpostulante', right_on='idpostulante',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ======================================================================\n",
    "\n",
    "## 1.3 - Resumen y cuestiones a tener en cuenta sobre el informe.\n",
    "\n",
    "En primer instancia contamos con la siguiente información para poder trabajar, por un lado tenemos los postulantes que son las personas que se registran, sobre las cuales tenemos tanto su nivel educativo, su fecha de nacimiento como así también su género, sobre estos datos los hemos limpiado y armado rangos de edades como así también hemos mantenido los duplicados en los niveles educativos puesto que para algunos informes nos pueden ser de utilidad, para aquellos informes que por el contrario nos resulte redundante o genere algún tipo de ruido hemos optado por filtrarlos y que solo quede un registro por postulante.\n",
    "\n",
    "Sobre los avisos vemos que tenemos tanto la información de si este se encuentra online como no, lo que nos da la pauta para saber si está en vigencia, por otro lado tenemos mucha información sobre el area de trabajo, el nivel de experiencia que requiere el puesto, también tenemos el nombre de la empresa (o grupo de empresas). todo sobre lo cual se pueden aplicar diversa cantidad de filtros o artilugios para limpiar los datos y poder generar gráficos más legibles y útiles.\n",
    "\n",
    "Tenemos datos tanto de las visitas como de las postulaciones en sí, ambos se pueden trabajar de manera similar puesto que el análisis que hacemos sobre uno puede hacerse de manera análoga sobre el otro, lo que nos lleva a tomar medidas similares a la hora de normalizar datos como ser la fecha de ocurrencia, como así también la información que obtenemos del detalle referente al aviso que se esta postulando o viendo. \n",
    "\n",
    "## ======================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
